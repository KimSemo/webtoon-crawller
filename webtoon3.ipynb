{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea17eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "#from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#글꼴설정\n",
    "matplotlib.rcParams['font.family'] ='Malgun Gothic' # 폰트설정\n",
    "matplotlib.rcParams['font.size'] = 15 # 글자크기\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False \n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "web_url = ['https://comic.naver.com/webtoon/detail?titleId=81482&no=719']\n",
    "\n",
    "num_Data = []\n",
    "page_num = []\n",
    "last_num = []\n",
    "try:\n",
    "    # URL리스트 입력시 해당 웹툰 '페이지 번호' 및 '마지막화' Data를 반환하는 함수\n",
    "    def Webtoon_URL(object): # object에 다가는 수집한 'web_url'리스트 대입\n",
    "        global page_num\n",
    "        global last_num\n",
    "        for i in object:\n",
    "            url_split = i.split('&')\n",
    "            for j in url_split:\n",
    "                url_Data = j.split('=')\n",
    "                num_Data.append(int(url_Data[1]))\n",
    "        for i in range(len(num_Data)):\n",
    "            if i % 2 == 0:\n",
    "                page_num.append(num_Data[i])\n",
    "            else:\n",
    "                last_num.append(num_Data[i])\n",
    "        return page_num, last_num\n",
    "\n",
    "    Webtoon_URL(web_url)\n",
    "\n",
    "    # 크롤링 함수\n",
    "    def crawlling(PN, No): \n",
    "        url=\"https://comic.naver.com/webtoon/detail?titleId=\" + str(page_num[PN]) + \"&no=\" + str(No)\n",
    "        browser.get(url)\n",
    "        Name = browser.find_element(By.XPATH,\"/html/body/div/div[2]/div/div[1]/div[1]/div[2]/h2/span[1]\").text\n",
    "        ge = browser.find_element(By.XPATH,\"/html/body/div/div[2]/div/div[1]/div[1]/div[2]/p[2]/span[1]\").text\n",
    "        star = browser.find_element(By.XPATH,\"/html/body/div/div[2]/div/div[1]/div[4]/dl/dd[1]/div/span[2]/strong\").text\n",
    "        star_ap = browser.find_element(By.XPATH,\"/html/body/div/div[2]/div/div[1]/div[4]/dl/dd[1]/div/span[3]/em\").text\n",
    "        time.sleep(1)\n",
    "        browser.switch_to.frame(\"commentIframe\")\n",
    "        reply_total=browser.find_element(By.XPATH,\"/html/body/div/div/div[1]/span\").text\n",
    "        reply_total = reply_total.replace(',','')\n",
    "        webtoon_data.append([No, Name, ge, float(star), int(star_ap), int(reply_total)])\n",
    "        return webtoon_data\n",
    "\n",
    "    # webtoon_data 리스트를 이용해 데이터프레임 만들고 엑셀 파일로 변경하는 함수\n",
    "    def df_to_excel(data_list): # 인자를 리스트명으로 하기\n",
    "        global pd_data\n",
    "        columns = ['화','제목', '장르', '별점','별점 참여자 수', '댓글 수']\n",
    "        pd_data = pd.DataFrame(data_list, columns = columns)\n",
    "        pd_data_episode = pd_data.set_index('화') # '화'를 인덱스로 설정한 데이터프레임\n",
    "        special_Chars = ['\\ ', '| ','/ ','? ','\" ','* ',': ','< ','> ']\n",
    "        for i in special_Chars:\n",
    "            data_list[0][1] = data_list[0][1].replace(i,'')\n",
    "        name = data_list[0][1]\n",
    "        pd_data_episode.to_excel('./'+name+'_web_toon.xlsx', index = True)\n",
    "        return pd_data\n",
    "\n",
    "    # 시각화 함수\n",
    "    def Web_crawlling_plot(data_F):\n",
    "        #sublpot설정\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        #별점 참여자수 , 댓글 수 하나의 그래프로 표현\n",
    "        axs[0].plot(data_F['화'], data_F['별점 참여자 수'],'b', label='별점 참여자 수')\n",
    "        axs[0].plot(data_F['화'], data_F['댓글 수'],'r', label='댓글 수')\n",
    "        axs[0].set_xlabel('화')\n",
    "        axs[0].set_ylabel('별점 참여자 수')\n",
    "        axs[0].set_title('별점 참여자수 와 댓글 수')\n",
    "        axs[0].legend()\n",
    "        #별점 그래프로 표현\n",
    "        axs[1].plot(data_F['화'], data_F['별점'],'g',label='별점')\n",
    "        axs[1].set_xlabel('화')\n",
    "        axs[1].set_ylabel('별점')\n",
    "        axs[1].set_title('별점')\n",
    "        axs[1].legend()\n",
    "        plt.suptitle(data_F['제목'][0], fontsize=30, fontweight =\"bold\")\n",
    "        plt.show()\n",
    "\n",
    "    for i in range(len(page_num)):\n",
    "        webtoon_data = []\n",
    "        if last_num[i] <= 100: # 100화 이하 작품\n",
    "            for num in range(1, last_num[i]+1):\n",
    "                crawlling(i, num)\n",
    "            df_to_excel(webtoon_data)\n",
    "            Web_crawlling_plot(pd_data)\n",
    "\n",
    "        elif (last_num[i] > 100) & (last_num[i] <= 150): # 101화 ~ 150화까지 작품\n",
    "            # 작품 앞 부분 크롤링\n",
    "            for num in range(1,51):\n",
    "                crawlling(i, num)\n",
    "            time.sleep(2)\n",
    "            # 작품 뒷 부분 크롤링\n",
    "            for num in range(last_num[i]-49, last_num[i]+1):\n",
    "                crawlling(i, num)\n",
    "            df_to_excel(webtoon_data)\n",
    "            Web_crawlling_plot(pd_data)\n",
    "\n",
    "        elif (last_num[i] > 150) & (last_num[i] <= 200): # 101화 ~ 150화까지 작품\n",
    "            # 작품 앞 부분 크롤링\n",
    "            for num in range(1,76):\n",
    "                crawlling(i, num)\n",
    "            time.sleep(2)\n",
    "            # 작품 뒷 부분 크롤링\n",
    "            for num in range(last_num[i]-74, last_num[i]+1):\n",
    "                crawlling(i, num)\n",
    "            df_to_excel(webtoon_data)\n",
    "            Web_crawlling_plot(pd_data)\n",
    "\n",
    "        else: # 201화 이상 작품\n",
    "            # 작품 앞 부분 크롤링\n",
    "            for num in range(1,101):\n",
    "                crawlling(i, num)\n",
    "            time.sleep(2)\n",
    "            # 작품 뒷 부분 크롤링\n",
    "            for num in range(last_num[i]-99, last_num[i]+1):\n",
    "                crawlling(i, num)\n",
    "            df_to_excel(webtoon_data)\n",
    "            Web_crawlling_plot(pd_data)\n",
    "except KeyboardInterrupt:\n",
    "    print('KeyboardInterrupt')\n",
    "except NoSuchElementException:\n",
    "    print('NoSuchElementException')\n",
    "#except SystemExit:\n",
    "    #print('SystemExit')\n",
    "#except ZeroDivisionError:\n",
    "    #print('ZeroDivisionError')\n",
    "#except RemoteDisconnected:\n",
    "    #print('RemoteDisconnected')\n",
    "except ProtocolError:\n",
    "    print('ProtocolError')\n",
    "except ConnectionRefusedError:\n",
    "    print('ConnectionRefusedError')\n",
    "except MaxRetryError:\n",
    "    print('MaxRetryError')\n",
    "#예외처리 중간에 끊겼을때 뜨는 에러, 차단당했을때 뜨는 에러, 읽어드릴 데이터가 없을때 뜨는 에러 등 발생할 수 있는 다양한 에러에 대비한 \n",
    "#예외처리입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-of-test",
   "language": "python",
   "name": "testoftest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
